<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Exploring Socially Robot Navigation via LLM-Based Human Interaction">
  <meta name="keywords" content="DRL, LLM, Robot Navigation,HCI">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta property="og:title" content="Exploring Socially Robot Navigation via LLM-Based Human Interaction">
  <meta property="og:type" content="website">
  <meta property="og:site_name" content="Exploring Socially Robot Navigation via LLM-Based Human Interaction">
  <meta property="og:image" content="https://hsacllm.github.io/static/images/Fig_overview_cartoon2.png" />
  <meta property="og:image:type" content="image/png" />
  <meta property="og:image:width" content="2888" />
  <meta property="og:image:height" content="1282" />
  <meta property="og:url" content="https://hsacllm.github.io" />
  <meta property="og:description" content="Project page for Exploring Socially Robot Navigation via LLM-Based Human Interaction" />


  <title>Exploring Socially Robot Navigation via LLM-Based Human Interaction</title>

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
            new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
          j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
          'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-W4VQD8T3');</script>
  <!-- End Google Tag Manager -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/web_icon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-W4VQD8T3"
                  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Exploring Socially Robot Navigation via LLM-Based Human Interaction</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://wencc.xyz/">Congcong Wen</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.yifanliubeam.com/">Yifan Liu</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://wenyuhan-lina.github.io/">Wenyu Han</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/geeta-chandra-raju-bethala/">Geeta Chandra Raju Bethala</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://yifang.org/group.html">Zheng Peng</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://yushen-liu.github.io/">Yu-Shen Liu</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://yifang.org/group.html">Yi Fang</a><sup>2</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>NYUAD Center for Artificial Intelligence and Robotics</span>
            <span class="author-block"><sup>2</sup>NYU Tandon school of engineering</span>
            <span class="author-block"><sup>3</sup>Tsinghua University Shool of Software</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
<!--              <span class="link-block">-->
<!--                <a href="https://arxiv.org/abs/2011.12948"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="ai ai-arxiv"></i>-->
<!--                  </span>-->
<!--                  <span>arXiv</span>-->
<!--                </a>-->
<!--              </span>-->
              <!-- Video Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
<!--              &lt;!&ndash; Code Link. &ndash;&gt;-->
<!--              <span class="link-block">-->
<!--                <a href="https://github.com/google/nerfies"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="fab fa-github"></i>-->
<!--                  </span>-->
<!--                  <span>Code</span>-->
<!--                  </a>-->
<!--              </span>-->
<!--              &lt;!&ndash; Dataset Link. &ndash;&gt;-->
<!--              <span class="link-block">-->
<!--                <a href="https://github.com/google/nerfies/releases/tag/0.1"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="far fa-images"></i>-->
<!--                  </span>-->
<!--                  <span>Data</span>-->
<!--                  </a>-->
<!--              </span>-->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/Fig_overview_cartoon2.png" />
      <h2 class="subtitle has-text-centered">
        Strategies used to avoid incoming collision with
        pedestrians. Left: Detour for a longer route to prevent col
        lision. Middle: Beeping to alert pedestrians and create
        space for the robot. Right: Interactive voice interaction,
        enabling proactive avoidance requests from either the robot
        or pedestrians.
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Visual Effects. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3">HSAC-LLM (Active request)</h2>
          <p>
            The Robot proactively sends voice avoidance requests after detecting collision risk.
            Ask the pedestrian margin to his closer side.
            <br>
            <br>
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/hallway_active.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <div class="column">
        <h2 class="title is-3">HSAC-LLM (Passive respond)</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              After receiving the pedestrian's state of his moving trajectory to the left side,
              the robot promptly shifts its position to the opposite side to avert a collision
              and responds with its next intended move.
            </p>
            <video id="matting-video" autoplay controls muted loop playsinline="100%">
              <source src="./static/videos/hallway_passive_on_your_left_new.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div>
    <!--/ Matting. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Robot navigation is an important research field
            with applications in various domains. However, traditional
            approaches often prioritize efficiency and obstacle avoidance,
            neglecting a nuanced understanding of human behavior or
            intent in shared spaces. With the rise of service robots, thereâ€™s
            an increasing emphasis on endowing robots with the capability
            to navigate and interact in complex real-world environments.
            Socially aware navigation has recently become a key research
            area. However, existing work either predicts pedestrian move-
            ments or simply emits alert signals to pedestrians, falling
            short of facilitating genuine interactions between humans and
            robots. In this paper, we introduce the Hybrid Soft Actor-
            Critic with Large Language Model (HSAC-LLM), a novel
            model for robot socially aware navigation that seamlessly
            integrates deep reinforcement learning and large language
            models, which concurrently handles the robotâ€™s continuous and
            discrete actions. When a collision risk with a pedestrian is
            detected, it initiates a conversation either by emitting speech or
            receiving the pedestrianâ€™s speech. After the dialogue concludes,
            the robot adjusts its motion based on the conversationâ€™s
            outcome. Experimental results in a 2D simulation and Gazebo
            environment demonstrate that HSAC-LLM not only efficiently
            enables interaction with humans but also exhibits superior
            performance in navigation and obstacle avoidance compared
            to state-of-the-art DRL algorithms. We believe this innovative
            paradigm opens up new avenues for effective and socially aware
            human-robot interactions in dynamic environments.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <video autoplay controls muted loop playsinline width="100%">
            <source src="static/videos/video_demo_all.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Approach</h2>
        <div class="content has-text-justified has-text-centered">
          <img src="static/images/Fig_flowchart_v2.png" />
          <h3 class="title is-4">Preprocessing</h3>
          <p>
            Raw observations like radar scans, pedestrian position, and speed information from the environment
            will be processed by <i>Img_PreNet</i> built by convolutional and fully connected layers. Pedestrian's vocal
            messages will be handled by <i>Lang_PreNet</i> built with LLM into action state vectors. Finally <i>State_PreNet</i>
            built by one fully connected layer will combine previously processed data with the robot's position info into a
            512-dimensional vector state used for the HSAC-LLM algorithm.
          </p>
          <h3 class="title is-4">HSAC(Hybrid Soft Actor Critic) Module</h3>
          <p>
            The behavior of the robot involves both continuous and discrete elements. We categorize
            the robotâ€™s motion controls, angular and linear velocities,
            as continuous actions, while post-interaction decisions are
            discrete actions. HSAC was used to model both continuous and discrete
            robot actions.
          </p>
          <h3 class="title is-4">LLM(Large Language Model) Module</h3>
          <img src="static/images/Fig_LLM_detail.png" />
          <p>
            LLM was introduced to serve as a conduit between discrete action codes and intuitive voice
            messages. Through the presentation of prompts that encapsulate the contextual information
            and environment dynamics,
            coupled with dialogue examples, the LLM performs a two-way translation.
            This translation facilitates the transformation
            between action code and the respective voice messages
            from both pedestrians and the robot.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">


      <!-- Animation. -->
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">ROS simulation with TurtleBot</h2>

          <!-- Re-rendering. -->
          <h3 class="title is-4">Crosswalk Environment</h3>
          <br>
          <div class="columns is-vcentered interpolation-panel">
            <div class="column  has-text-centered">
              <video autoplay controls muted loop playsinline height="100%">
                <source src="static/videos/hallway_active.mp4" type="video/mp4">
              </video>
              <p>
                Proactive made by robot
                <br>
                Robot: "Could you move to your right please?"
                <br>
                Pedestrian: "Sure I will do that!"
              </p>
            </div>
            <div class="column  has-text-centered">
              <video autoplay controls muted loop playsinline height="100%">
                <source src="static/videos/hallway_passive_on_your_left_new.mp4" type="video/mp4">
              </video>
              <p>
                Proactive made by pedestrian
                <br>
                Pedestrian: "On your left!"
                <br>
                Robot: "I will shift to my right."
              </p>
            </div>
          </div>
          <div class="columns is-vcentered interpolation-panel">
            <div class="column  has-text-centered">
              <video autoplay controls muted loop playsinline height="100%">
                <source src="static/videos/hallway_passive_moving_towards_your_right_side.mp4" type="video/mp4">
              </video>
              <p>
                Proactive made by pedestrian
                <br>
                Pedestrian: "Moving towards your right side!"
                <br>
                Robot: "I shift to the left then."
              </p>
            </div>
            <div class="column  has-text-centered">
              <video autoplay controls muted loop playsinline height="100%">
                <source src="static/videos/hallway_passive_on_your_right.mp4" type="video/mp4">
              </video>
              <p>
                Proactive made by pedestrian
                <br>
                Pedestrian: "On your right!"
                <br>
                Robot: "I will move to my left."
              </p>
            </div>
          </div>

          <h3 class="title is-4">Crosswalk Environment</h3>
          <br>
          <div class="columns is-vcentered interpolation-panel">
            <div class="column  has-text-centered">
              <video autoplay controls muted loop playsinline height="100%">
                <source src="static/videos/crosswalk_active.mp4" type="video/mp4">
              </video>
              <p>
                Proactive made by robot
                <br>
                Robot: "Could you please stop so I can pass?"
                <br>
                Pedestrian: "Sure, go ahead!"
                <br>
              </p>
            </div>
            <div class="column  has-text-centered">
              <video autoplay controls muted loop playsinline height="100%">
                <source src="static/videos/crosswalk_passive_could_you_let_me_pass_first.mp4" type="video/mp4">
              </video>
              <p>
                Proactive made by pedestrian
                <br>
                Pedestrian: "Could you let me pass first?"
                <br>
                Robot: "Of course, I will stop."
              </p>
            </div>
          </div>

          <div class="columns is-vcentered interpolation-panel">
            <div class="column  has-text-centered">
              <video autoplay controls muted loop playsinline height="100%">
                <source src="static/videos/crosswalk_passive_I_am_already_late_for_my_work.mp4" type="video/mp4">
              </video>
              <p>
                Proactive made by pedestrian
                <br>
                Pedestrian: "I am already late for my work!"
                <br>
                Robot: "Ok I will stop."
              </p>
            </div>
            <div class="column  has-text-centered">
              <video autoplay controls muted loop playsinline height="100%">
                <source src="static/videos/crosswalk_passive_I_am_in_a_hurry.mp4" type="video/mp4">
              </video>
              <p>
                Proactive made by pedestrian
                <br>
                Pedestrian: "I am in a hurry!"
                <br>
                Robot: "Ok, I will stop to left you pass."
              </p>
            </div>
          </div>


        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">

  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Real world experiments</h2>

    <div class="columns">
      <!-- First video -->
      <div class="column">
        <div class="publication-video">
          <video autoplay controls muted loop playsinline width="100%">
            style="width: 100%; max-width: 250px; height: auto; object-fit: contain;">
            <source src="static/videos/hall_real_walk_new.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <!-- Second video -->
      <div class="column">
        <div class="publication-video">
          <video autoplay controls muted loop playsinline width="100%">
            style="width: 100%; max-width: 250px; height: auto; object-fit: contain;">
            <source src="static/videos/hall_walk_old.mp4" type="video/mp4">
          </video>
        </div>
      </div>


        

      </div>
    </div>
  </div>
</section>




<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{hsacllm2024,
  author    = {Congcong Wen, Yifan Liu, Wenyu Han, Geeta Chandra Raju Bethala, Zheng Peng, Yu-Shen Liu and Yi Fang},
  title     = {Exploring Socially Robot Navigation via LLM-Based Human Interaction},
  journal   = {},
  year      = {2023},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p> Website borrowed from <a href="https://github.com/nerfies/nerfies.github.io">NeRFies</a> under a <a
                  href="https://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0
            International</a>
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
