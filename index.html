<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Exploring Socially Robot Navigation via LLM-Based Human Interaction">
  <meta name="keywords" content="DRL, LLM, Robot Navigation,HCI">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta property="og:title" content="Exploring Socially Robot Navigation via LLM-Based Human Interaction">
  <meta property="og:type" content="website">
  <meta property="og:site_name" content="Exploring Socially Robot Navigation via LLM-Based Human Interaction">
  <meta property="og:image" content="https://hsacllm.github.io/static/images/Fig_overview_cartoon2.png" />
  <meta property="og:image:type" content="image/png" />
  <meta property="og:image:width" content="2888" />
  <meta property="og:image:height" content="1282" />
  <meta property="og:url" content="https://hsacllm.github.io" />
  <meta property="og:description" content="Project page for Exploring Socially Robot Navigation via LLM-Based Human Interaction" />


  <title>Exploring Socially Robot Navigation via LLM-Based Human Interaction</title>

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
            new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
          j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
          'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-W4VQD8T3');</script>
  <!-- End Google Tag Manager -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/web_icon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-W4VQD8T3"
                  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Exploring Socially Robot Navigation via LLM-Based Human Interaction</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://wencc.xyz/">Congcong Wen</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.yifanliubeam.com/">Yifan Liu</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://wenyuhan-lina.github.io/">Wenyu Han</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/geeta-chandra-raju-bethala/">Geeta Chandra Raju Bethala</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://yifang.org/group.html">Zheng Peng</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://yushen-liu.github.io/">Yu-Shen Liu</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://yifang.org/group.html">Yi Fang</a><sup>2</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>NYUAD Center for Artificial Intelligence and Robotics</span>
            <span class="author-block"><sup>2</sup>NYU Tandon school of engineering</span>
            <span class="author-block"><sup>3</sup>Tsinghua University Shool of Software</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
<!--              <span class="link-block">-->
<!--                <a href="https://arxiv.org/abs/2011.12948"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="ai ai-arxiv"></i>-->
<!--                  </span>-->
<!--                  <span>arXiv</span>-->
<!--                </a>-->
<!--              </span>-->
              <!-- Video Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
<!--              &lt;!&ndash; Code Link. &ndash;&gt;-->
<!--              <span class="link-block">-->
<!--                <a href="https://github.com/google/nerfies"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="fab fa-github"></i>-->
<!--                  </span>-->
<!--                  <span>Code</span>-->
<!--                  </a>-->
<!--              </span>-->
<!--              &lt;!&ndash; Dataset Link. &ndash;&gt;-->
<!--              <span class="link-block">-->
<!--                <a href="https://github.com/google/nerfies/releases/tag/0.1"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="far fa-images"></i>-->
<!--                  </span>-->
<!--                  <span>Data</span>-->
<!--                  </a>-->
<!--              </span>-->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/Fig_overview_cartoon2.png" />
      <h2 class="subtitle has-text-centered">
        Strategies used to avoid incoming collision with
        pedestrians. Left: Detour for a longer route to prevent col
        lision. Middle: Beeping to alert pedestrians and create
        space for the robot. Right: Interactive voice interaction,
        enabling proactive avoidance requests from either the robot
        or pedestrians.
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Visual Effects. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3">HSAC-LLM (Active request)</h2>
          <p>
            The Robot proactively sends voice avoidance requests after detecting collision risk.
            Ask the pedestrian margin to his closer side.
            <br>
            <br>
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/hallway_active.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <div class="column">
        <h2 class="title is-3">HSAC-LLM (Passive respond)</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              After receiving the pedestrian's state of his moving trajectory to the left side,
              the robot promptly shifts its position to the opposite side to avert a collision
              and responds with its next intended move.
            </p>
            <video id="matting-video" autoplay controls muted loop playsinline="100%">
              <source src="./static/videos/hallway_passive_on_your_left_new.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div>
    <!--/ Matting. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Robot navigation is an important research field
            with applications in various domains. However, traditional
            approaches often prioritize efficiency and obstacle avoidance,
            neglecting a nuanced understanding of human behavior or
            intent in shared spaces. With the rise of service robots, there’s
            an increasing emphasis on endowing robots with the capability
            to navigate and interact in complex real-world environments.
            Socially aware navigation has recently become a key research
            area. However, existing work either predicts pedestrian move-
            ments or simply emits alert signals to pedestrians, falling
            short of facilitating genuine interactions between humans and
            robots. In this paper, we introduce the Hybrid Soft Actor-
            Critic with Large Language Model (HSAC-LLM), a novel
            model for robot socially aware navigation that seamlessly
            integrates deep reinforcement learning and large language
            models, which concurrently handles the robot’s continuous and
            discrete actions. When a collision risk with a pedestrian is
            detected, it initiates a conversation either by emitting speech or
            receiving the pedestrian’s speech. After the dialogue concludes,
            the robot adjusts its motion based on the conversation’s
            outcome. Experimental results in a 2D simulation and Gazebo
            environment demonstrate that HSAC-LLM not only efficiently
            enables interaction with humans but also exhibits superior
            performance in navigation and obstacle avoidance compared
            to state-of-the-art DRL algorithms. We believe this innovative
            paradigm opens up new avenues for effective and socially aware
            human-robot interactions in dynamic environments.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <video autoplay controls muted loop playsinline width="100%">
            <source src="static/videos/video_demo_all.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Approach</h2>
        <div class="content has-text-justified has-text-centered">
          <img src="static/images/Fig_flowchart_v2.png" />
          <h3 class="title is-4">Preprocessing</h3>
          <p>
            Raw observations like radar scans, pedestrian position, and speed information from the environment
            will be processed by <i>Img_PreNet</i> built by convolutional and fully connected layers. Pedestrian's vocal
            messages will be handled by <i>Lang_PreNet</i> built with LLM into action state vectors. Finally <i>State_PreNet</i>
            built by one fully connected layer will combine previously processed data with the robot's position info into a
            512-dimensional vector state used for the HSAC-LLM algorithm.
          </p>
          <h3 class="title is-4">HSAC(Hybrid Soft Actor Critic) Module</h3>
          <p>
            The behavior of the robot involves both continuous and discrete elements. We categorize
            the robot’s motion controls, angular and linear velocities,
            as continuous actions, while post-interaction decisions are
            discrete actions. HSAC was used to model both continuous and discrete
            robot actions.
          </p>
          <h3 class="title is-4">LLM(Large Language Model) Module</h3>
          <img src="static/images/Fig_LLM_detail.png" />
          <p>
            LLM was introduced to serve as a conduit between discrete action codes and intuitive voice
            messages. Through the presentation of prompts that encapsulate the contextual information
            and environment dynamics,
            coupled with dialogue examples, the LLM performs a two-way translation.
            This translation facilitates the transformation
            between action code and the respective voice messages
            from both pedestrians and the robot.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">


      <!-- Animation. -->
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">ROS simulation with TurtleBot</h2>

          <!-- Re-rendering. -->
          <h3 class="title is-4">Crosswalk Environment</h3>
          <br>
          <div class="columns is-vcentered interpolation-panel">
            <div class="column  has-text-centered">
              <video autoplay controls muted loop playsinline height="100%">
                <source src="static/videos/hallway_active.mp4" type="video/mp4">
              </video>
              <p>
                Proactive made by robot
                <br>
                Robot: "Could you move to your right please?"
                <br>
                Pedestrian: "Sure I will do that!"
              </p>
            </div>
            <div class="column  has-text-centered">
              <video autoplay controls muted loop playsinline height="100%">
                <source src="static/videos/hallway_passive_on_your_left_new.mp4" type="video/mp4">
              </video>
              <p>
                Proactive made by pedestrian
                <br>
                Pedestrian: "On your left!"
                <br>
                Robot: "I will shift to my right."
              </p>
            </div>
          </div>
          <div class="columns is-vcentered interpolation-panel">
            <div class="column  has-text-centered">
              <video autoplay controls muted loop playsinline height="100%">
                <source src="static/videos/hallway_passive_moving_towards_your_right_side.mp4" type="video/mp4">
              </video>
              <p>
                Proactive made by pedestrian
                <br>
                Pedestrian: "Moving towards your right side!"
                <br>
                Robot: "I shift to the left then."
              </p>
            </div>
            <div class="column  has-text-centered">
              <video autoplay controls muted loop playsinline height="100%">
                <source src="static/videos/hallway_passive_on_your_right.mp4" type="video/mp4">
              </video>
              <p>
                Proactive made by pedestrian
                <br>
                Pedestrian: "On your right!"
                <br>
                Robot: "I will move to my left."
              </p>
            </div>
          </div>

          <h3 class="title is-4">Crosswalk Environment</h3>
          <br>
          <div class="columns is-vcentered interpolation-panel">
            <div class="column  has-text-centered">
              <video autoplay controls muted loop playsinline height="100%">
                <source src="static/videos/crosswalk_active.mp4" type="video/mp4">
              </video>
              <p>
                Proactive made by robot
                <br>
                Robot: "Could you please stop so I can pass?"
                <br>
                Pedestrian: "Sure, go ahead!"
                <br>
              </p>
            </div>
            <div class="column  has-text-centered">
              <video autoplay controls muted loop playsinline height="100%">
                <source src="static/videos/crosswalk_passive_could_you_let_me_pass_first.mp4" type="video/mp4">
              </video>
              <p>
                Proactive made by pedestrian
                <br>
                Pedestrian: "Could you let me pass first?"
                <br>
                Robot: "Of course, I will stop."
              </p>
            </div>
          </div>

          <div class="columns is-vcentered interpolation-panel">
            <div class="column  has-text-centered">
              <video autoplay controls muted loop playsinline height="100%">
                <source src="static/videos/crosswalk_passive_I_am_already_late_for_my_work.mp4" type="video/mp4">
              </video>
              <p>
                Proactive made by pedestrian
                <br>
                Pedestrian: "I am already late for my work!"
                <br>
                Robot: "Ok I will stop."
              </p>
            </div>
            <div class="column  has-text-centered">
              <video autoplay controls muted loop playsinline height="100%">
                <source src="static/videos/crosswalk_passive_I_am_in_a_hurry.mp4" type="video/mp4">
              </video>
              <p>
                Proactive made by pedestrian
                <br>
                Pedestrian: "I am in a hurry!"
                <br>
                Robot: "Ok, I will stop to left you pass."
              </p>
            </div>
          </div>


        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">

  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Real world experiments</h2>

    <div class="columns">
      <!-- First video -->
      <div class="column">
        <div class="publication-video">
          <video autoplay controls muted loop playsinline width="100%">
            style="width: 100%; max-width: 250px; height: auto; object-fit: contain;">
            <source src="static/videos/hall_real_walk_new.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <!-- Second video -->
      <div class="column">
        <div class="publication-video">
          <video autoplay controls muted loop playsinline width="100%">
            style="width: 100%; max-width: 250px; height: auto; object-fit: contain;">
            <source src="static/videos/hall_walk_old.mp4" type="video/mp4">
          </video>
        </div>
      </div>


        

      </div>
    </div>
  </div>
</section>




<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{hsacllm2024,
  author    = {Congcong Wen, Yifan Liu, Wenyu Han, Geeta Chandra Raju Bethala, Zheng Peng, Yu-Shen Liu and Yi Fang},
  title     = {Exploring Socially Robot Navigation via LLM-Based Human Interaction},
  journal   = {},
  year      = {2023},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p> Website borrowed from <a href="https://github.com/nerfies/nerfies.github.io">NeRFies</a> under a <a
                  href="https://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0
            International</a>
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
